{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/yiji/Desktop/ybigta/project/해커톤/agi_ybgirls/agi_ybgirls/lib/python3.11/site-packages (from beautifulsoup4) (4.13.0)\n",
      "Using cached beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.13.3 soupsieve-2.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔑 최상위 keys: dict_keys(['api', 'content', 'elements', 'merged_elements', 'model', 'ocr', 'usage'])\n",
      "🔑 content keys: dict_keys(['html', 'markdown', 'text'])\n",
      "api: <class 'str'>\n",
      "content: <class 'dict'>\n",
      "  └─ html: <class 'str'>\n",
      "  └─ markdown: <class 'str'>\n",
      "  └─ text: <class 'str'>\n",
      "elements: <class 'list'>\n",
      "merged_elements: <class 'list'>\n",
      "model: <class 'str'>\n",
      "ocr: <class 'bool'>\n",
      "usage: <class 'dict'>\n",
      "  └─ pages: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../Database/input/구강_구개열_crop_parsing.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 최상위 키 확인\n",
    "print(\"🔑 최상위 keys:\", data.keys())\n",
    "\n",
    "# content 내부 키\n",
    "if 'content' in data:\n",
    "    print(\"🔑 content keys:\", data['content'].keys())\n",
    "\n",
    "# content 안에 'elements'가 있다면, 첫 번째 요소 구조 확인\n",
    "if 'elements' in data['content']:\n",
    "    print(\"📌 elements[0] 예시:\")\n",
    "    print(data['content']['elements'][0].keys())\n",
    "\n",
    "for k, v in data.items():\n",
    "    print(f\"{k}: {type(v)}\")\n",
    "    if isinstance(v, dict):\n",
    "        for kk in v.keys():\n",
    "            print(f\"  └─ {kk}: {type(v[kk])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 병명 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅병명: 구개열\n"
     ]
    }
   ],
   "source": [
    "html = data['content']['html']\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 병명 추출 (h1 없을 때 대비)\n",
    "disease_tag = soup.find(\"h1\")\n",
    "\n",
    "if disease_tag is None:\n",
    "    print(\"[⚠️경고] h1 태그를 찾을 수 없습니다.\")\n",
    "    \n",
    "    # h1이 없으면 font-size:22px인 첫 <p>나 <header>를 찾아서 병명 추출\n",
    "    for tag in soup.find_all([\"p\", \"header\"]):\n",
    "        style = tag.get(\"style\", \"\")\n",
    "        if \"font-size:22px\" in style:\n",
    "            disease_tag = tag\n",
    "            print(\"[⚠️] fontsize 22 태그로 추출했습니다.\")\n",
    "\n",
    "            break\n",
    "\n",
    "# 병명 최종 추출\n",
    "if disease_tag:\n",
    "  disease_name = disease_tag.get_text(strip=True)\n",
    "else:\n",
    "  disease_name = \"Unknown Disease\"\n",
    "  print(\"[⚠️경고] 병명 추출 실패: h1 또는 font-size:22px 태그를 찾을 수 없습니다.\")\n",
    "\n",
    "# 3. 그래도 없으면 '• 콘텐츠명 :' 포함된 텍스트에서 추출\n",
    "if not disease_name:\n",
    "    for tag in soup.find_all(\"p\"):\n",
    "        text = tag.get_text(strip=True)\n",
    "        if \"• 콘텐츠명\" in text:\n",
    "            # \"• 콘텐츠명 : 구개열\" 형식에서 오른쪽 값만 추출\n",
    "            match = re.search(r\"콘텐츠명\\s*:\\s*(.+)\", text)\n",
    "            if match:\n",
    "                disease_name = match.group(1).strip()\n",
    "                break\n",
    "            \n",
    "print(f'✅병명: {disease_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내용 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "current_section = None\n",
    "current_text = []\n",
    "\n",
    "first_page_font_threshold = 22\n",
    "other_page_font_threshold = 18\n",
    "\n",
    "for elem in data['elements']:\n",
    "    html = elem.get(\"content\", {}).get(\"html\", \"\")\n",
    "    text = BeautifulSoup(html, \"html.parser\").get_text(strip=True)\n",
    "    page = elem.get(\"page\", 1)\n",
    "    category = elem.get(\"category\", \"\")\n",
    "    style = \"\"\n",
    "    \n",
    "    # style 정보 추출\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    tag = soup.find()\n",
    "    if tag:\n",
    "        style = tag.get(\"style\", \"\")\n",
    "\n",
    "    # font-size 추출\n",
    "    font_size = 0\n",
    "    if \"font-size:\" in style:\n",
    "        try:\n",
    "            font_size = int(style.split(\"font-size:\")[1].replace(\"px\", \"\").strip())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 페이지별 기준 적용\n",
    "    threshold = first_page_font_threshold if page == 1 else other_page_font_threshold\n",
    "    is_heading = (category.startswith(\"heading\") or font_size >= threshold)\n",
    "\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    if is_heading:\n",
    "        if current_section and current_text:\n",
    "            chunks.append({\n",
    "                \"disease\": disease_name,\n",
    "                \"section\": current_section,\n",
    "                \"content\": \"\\n\".join(current_text),\n",
    "                \"page\": page\n",
    "            })\n",
    "            current_text = []\n",
    "\n",
    "        current_section = text\n",
    "    else:\n",
    "        current_text.append(text)\n",
    "\n",
    "# 마지막 섹션 저장\n",
    "if current_section and current_text:\n",
    "    chunks.append({\n",
    "        \"disease\": disease_name,\n",
    "        \"section\": current_section,\n",
    "        \"content\": \"\\n\".join(current_text),\n",
    "        \"page\": page\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"done!\")\n",
    "\n",
    "# 결과를 JSON 파일로 저장 (가독성 있게)\n",
    "with open(\"../../Database/output/processed/구개열_crop_test.json\", \"w\", encoding=\"utf-8\") as f_json:\n",
    "    json.dump(chunks, f_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 또는 텍스트 파일로 보기 좋게 저장\n",
    "with open(\"../../Database/output/processed/구개열_crop_test.txt\", \"w\", encoding=\"utf-8\") as f_txt:\n",
    "    for chunk in chunks:\n",
    "        f_txt.write(f\"[{chunk['section']}]\\n\")\n",
    "        f_txt.write(chunk[\"content\"] + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qna 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: ../../Database/output/processed_final/구개열_crop_testqa_split.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 파일 경로\n",
    "input_path = \"../../Database/output/processed/구개열_crop_test.json\"\n",
    "output_path = \"../../Database/output/processed_final/구개열_crop_testqa_split.json\"\n",
    "\n",
    "\n",
    "# ✅ Q/A 분리 함수\n",
    "def split_qa_section(disease, content, page):\n",
    "    qa_chunks = []\n",
    "\n",
    "    # 줄바꿈 정리\n",
    "    content = content.replace(\"A.\\\\n\", \"A.\\n\").replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "    # Q/A 블록 추출\n",
    "    qa_blocks = re.split(r\"(Q\\..*?)\\nA\\.\", content)\n",
    "    qa_blocks = [b.strip() for b in qa_blocks if b.strip()]\n",
    "\n",
    "    for i in range(0, len(qa_blocks)-1, 2):\n",
    "        question = qa_blocks[i]\n",
    "        answer = qa_blocks[i+1]\n",
    "        qa_chunks.append({\n",
    "            \"disease\": disease,\n",
    "            \"section\": question,\n",
    "            \"content\": answer,\n",
    "            \"page\": page\n",
    "        })\n",
    "\n",
    "    return qa_chunks\n",
    "\n",
    "# 🧾 공공누리 문구 (정확히 비교)\n",
    "PUBLIC_NOTICE = '본 공공저작물은 공공누리 \"출처표시+상업적이용금지+변경금지\" 조건에 따라 이용할 수 있습니다.'\n",
    "\n",
    "# 🔽 1. 기존 파일 불러오기\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "# 🔄 2. 정제된 chunks 만들기\n",
    "new_chunks = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    disease = chunk[\"disease\"]\n",
    "    section = chunk[\"section\"].strip()\n",
    "\n",
    "    # ❌ 섹션이 질병명과 같거나 공공누리 문구이면 제외\n",
    "    if section == disease or section == PUBLIC_NOTICE:\n",
    "        continue\n",
    "\n",
    "    # 🔄 자주하는 질문은 Q/A 분할\n",
    "    if section == \"자주하는 질문\":\n",
    "        split_chunks = split_qa_section(\n",
    "            disease=disease,\n",
    "            content=chunk[\"content\"],\n",
    "            page=chunk.get(\"page\", 1)\n",
    "        )\n",
    "        new_chunks.extend(split_chunks)\n",
    "    else:\n",
    "        new_chunks.append(chunk)\n",
    "\n",
    "# 💾 3. 저장\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(new_chunks, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ 저장 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agi_ybgirls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
