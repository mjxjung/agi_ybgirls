# extractor.py

import re
from bs4 import BeautifulSoup
import os
import json
import pandas as pd
from datetime import datetime


def extract_disease_name(html: str) -> str:
    soup = BeautifulSoup(html, 'html.parser')
    EXCLUDE_TITLES = {"ìš”ì•½ë¬¸", "ê°œìš”", "ê°œìš”-ì •ì˜", "ì •ì˜", "ëª©ì°¨"}

    disease_tag = None

    # 1. h1 íƒœê·¸ ì¤‘ ì œì™¸ í‚¤ì›Œë“œ ì•„ë‹Œ ê²ƒ
    for tag in soup.find_all("h1"):
        text = tag.get_text(strip=True)
        if text and text not in EXCLUDE_TITLES and re.search(r"[ê°€-í£]", text):
            disease_tag = tag
            break

    # 2. font-size:22pxì¸ p/header ì¤‘ ì œì™¸ í‚¤ì›Œë“œ ì•„ë‹Œ ê²ƒ
    if disease_tag is None:
        for tag in soup.find_all(["p", "header"]):
            style = tag.get("style", "")
            text = tag.get_text(strip=True)
            if (
                "font-size:22px" in style and 
                text and 
                text not in EXCLUDE_TITLES and 
                re.search(r"[ê°€-í£]", text)
            ):
                disease_tag = tag
                print("[âš ï¸] fontsize 22px íƒœê·¸ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                break

    # 3. ì½˜í…ì¸ ëª…: êµ¬ê°œì—´ í˜•ì‹
    disease_name = disease_tag.get_text(strip=True) if disease_tag else ""
    if not disease_name.strip():
        for tag in soup.find_all("p"):
            text = tag.get_text(strip=True)
            if "ì½˜í…ì¸ ëª…" in text:
                match = re.search(r"ì½˜í…ì¸ ëª…\s*:\s*(.+)", text)
                if match:
                    disease_name = match.group(1).strip()
                    break

    if not disease_name.strip():
        disease_name = "Unknown Disease"
        print("âš ï¸ ë³‘ëª… ì¶”ì¶œ ì‹¤íŒ¨: ê¸°ë³¸ê°’ ë°˜í™˜")

    print(f"âœ… ë³‘ëª…: {disease_name}")
    return disease_name

def extract_sections(data: dict, disease_name: str) -> list[dict]:
    """
    ë¬¸ì„œ dataì—ì„œ ì„¹ì…˜ë³„ ë‚´ìš©ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜

    Args:
        data (dict): notebookì—ì„œ ë¶ˆëŸ¬ì˜¨ JSON ë°ì´í„°
        disease_name (str): ì¶”ì¶œëœ ë³‘ëª…

    Returns:
        list[dict]: ì„¹ì…˜ë³„ë¡œ ë‚˜ëˆˆ ë³‘ëª…, ì œëª©, ë³¸ë¬¸, í˜ì´ì§€ ì •ë³´ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ ì„¤ì •
    MAX_HEADING_LENGTH = 20
    first_page_font_threshold = 22
    other_page_font_threshold = 18

    chunks = []
    current_section = None
    current_text = []
    current_page = None

    for elem in data.get('elements', []):
        html = elem.get("content", {}).get("html", "")
        text = BeautifulSoup(html, "html.parser").get_text(strip=True)
        page = elem.get("page", 1)
        category = elem.get("category", "")
        style = ""

        # ìŠ¤íƒ€ì¼ì—ì„œ font-size ì¶”ì¶œ
        soup = BeautifulSoup(html, "html.parser")
        tag = soup.find()
        if tag:
            style = tag.get("style", "")
        
        font_size = 0
        if "font-size:" in style:
            try:
                font_size = int(style.split("font-size:")[1].replace("px", "").strip())
            except:
                pass

        # heading ì¡°ê±´
        threshold = first_page_font_threshold if page == 1 else other_page_font_threshold
        is_heading = (
            (category.startswith("heading") or font_size >= threshold)
            and len(text) <= MAX_HEADING_LENGTH
        )

        if not text:
            continue

        # âœ… ê·¸ë¦¼ ì²˜ë¦¬ ì˜ˆì™¸
        if text.startswith("<ê·¸ë¦¼") and ">" in text:
            match = re.match(r"<(.*?)>(.*)", text)
            if match:
                fig_section = match.group(1).strip()
                fig_content = match.group(2).strip()
                chunks.append({
                    "disease": disease_name,
                    "section": fig_section,
                    "content": fig_content,
                    "page": page
                })
            continue

        if is_heading:
            if current_section and current_text:
                chunks.append({
                    "disease": disease_name,
                    "section": current_section,
                    "content": "\n".join(current_text).strip(),
                    "page": current_page
                })
                current_text = []

            current_section = text
            current_page = page
        else:
            current_text.append(text)

    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
    if current_section and current_text:
        chunks.append({
            "disease": disease_name,
            "section": current_section,
            "content": "\n".join(current_text).strip(),
            "page": current_page
        })

        return chunks

def save_chunks_to_file(chunks: list[dict], folder_path: str, disease_name: str, original_filename: str):
    """
    í´ë” ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ chunksë¥¼ JSONê³¼ CSVë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.

    Parameters:
        chunks (list[dict]): ì„¹ì…˜ë³„ë¡œ ë¶„ë¥˜ëœ í…ìŠ¤íŠ¸ ë°ì´í„°
        folder_path (str): ì €ì¥í•  í´ë” ê²½ë¡œ
        disease_name (str): ë³‘ëª… (íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©ë¨)
    """
    # í´ë” ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(folder_path, exist_ok=True)

    # ë³‘ëª…ì— ë“¤ì–´ê°ˆ ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
    # safe_disease_name = "".join(c for c in disease_name if c.isalnum() or c in (" ", "_", "-")).strip().replace(" ", "_")

    # "êµ¬ê°•_êµ¬ë‚´ì—¼.json" â†’ "êµ¬ê°•_êµ¬ë‚´ì—¼"
    base_name = os.path.splitext(os.path.basename(original_filename))[0]
    filename = f"{base_name}_{disease_name}.json"
    save_path = os.path.join(folder_path, filename)

    # íƒ€ì„ìŠ¤íƒ¬í”„ (optional, ì´ë¦„ ì¶©ëŒ ë°©ì§€ìš©)
    # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ì €ì¥ ê²½ë¡œ ì§€ì •
    # json_path = os.path.join(folder_path, f"{safe_disease_name}.json")
    # csv_path = os.path.join(folder_path, f"{safe_disease_name}.csv")

    # ì €ì¥
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(chunks, f, ensure_ascii=False, indent=2)

    # pd.DataFrame(chunks).to_csv(csv_path, index=False)

    print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {save_path}")
    # print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {csv_path}")


def process_sections(chunks: list[dict]) -> list[dict]:
    """
    ì €ì¥ëœ ì„¹ì…˜ ë°ì´í„°ë¥¼ í›„ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    - ì§ˆë³‘ëª…ê³¼ ê°™ì€ ì œëª© ì œê±°
    - ê³µê³µëˆ„ë¦¬ ë¬¸êµ¬ ì œê±°
    - 'ìì£¼í•˜ëŠ” ì§ˆë¬¸' ì„¹ì…˜ì„ Q/A ìŒìœ¼ë¡œ ë¶„ë¦¬
    - ì„¹ì…˜ëª…ì´ 'ê·¸ë¦¼'ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì œì™¸
    - ë³¸ë¬¸ì— (ê·¸ë¦¼...) í˜•íƒœê°€ ìˆìœ¼ë©´ ì‚­ì œ
    - íŠ¹ì • ë¶ˆí•„ìš” ë¬¸êµ¬ ì œê±°
    - ìš”ì•½ë¬¸ì´ ë“±ë¡ì¼ìì¼ ê²½ìš° ì œê±°

    Parameters:
        chunks (list[dict]): ì €ì¥ëœ ì„¹ì…˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸

    Returns:
        list[dict]: í›„ì²˜ë¦¬ëœ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
    """

    def split_qa_section(disease, content, page):
        qa_chunks = []

        # ì¤„ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ê¸°
        lines = content.splitlines()

        question = None
        answer_lines = []

        for line in lines:
            line = line.strip()
            if line.startswith("Q."):
                # ì´ì „ QA ìŒ ì €ì¥
                if question and answer_lines:
                    qa_chunks.append({
                        "disease": disease,
                        "section": question,
                        "content": "\n".join(answer_lines).strip(),
                        "page": page
                    })
                    answer_lines = []

                question = line

            elif line.startswith("A") or line.startswith("A."):
                # A ë¼ì¸ ìì²´ëŠ” ì €ì¥í•˜ì§€ ì•Šê³ , ë‹¤ìŒ ì¤„ë¶€í„° answer ì‹œì‘
                continue

            elif question:
                answer_lines.append(line)

        # ë§ˆì§€ë§‰ QA ìŒ ì €ì¥
        if question and answer_lines:
            qa_chunks.append({
                "disease": disease,
                "section": question,
                "content": "\n".join(answer_lines).strip(),
                "page": page
            })

        return qa_chunks

    REMOVE_SECTIONS = {
        'ë³¸ ê³µê³µì €ì‘ë¬¼ì€ ê³µê³µëˆ„ë¦¬ "ì¶œì²˜í‘œì‹œ+ìƒì—…ì ì´ìš©ê¸ˆì§€+ë³€ê²½ê¸ˆì§€" ì¡°ê±´ì— ë”°ë¼ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        "ê°œì¸ì •ë³´ì²˜ë¦¬ë°©ì¹¨ ê°œì¸ì •ë³´ì´ìš©ì•ˆë‚´ ì €ì‘ê¶Œì •ì±… ë° ì›¹ì ‘ê·¼ì„±",
        "â€» ë³¸ í˜ì´ì§€ì—ì„œ ì œê³µí•˜ëŠ” ë‚´ìš©ì€ ì°¸ê³ ì‚¬í•­ì¼ ë¿ ê²Œì‹œë¬¼ì— ëŒ€í•œ ë²•ì ì±…ì„ì€ ì—†ìŒì„ ë°í˜€ë“œë¦½ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.",
        "[ 28159 ] ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œ í¥ë•êµ¬ ì˜¤ì†¡ì ì˜¤ì†¡ìƒëª…2ë¡œ 187 ì˜¤ì†¡ë³´ê±´ì˜ë£Œí–‰ì •íƒ€ìš´ ë‚´ ì§ˆë³‘ê´€ë¦¬ì²­ë¬¸ì˜ì‚¬í•­: 02-2030-6602 (í‰ì¼ 9:00-17:00, 12:00-13:00 ì œì™¸) / ê´€ë¦¬ì ì´ë©”ì¼ : nhis@korea.kr",
        "ì°¸ê³ ë¬¸í—Œ"
    }

    new_chunks = []

    for chunk in chunks:
        disease = chunk["disease"]
        section = chunk["section"].strip()
        content = chunk["content"].strip()

        # âŒ ì œê±° ì¡°ê±´
        if (
            section == disease or
            section.startswith("ê·¸ë¦¼") or
            section in REMOVE_SECTIONS or
            (section == "ìš”ì•½ë¬¸" and content.startswith("ë“±ë¡ì¼ì"))
        ):
            continue

        # âœ… ë³¸ë¬¸ì—ì„œ (ê·¸ë¦¼...) í˜•íƒœ ì œê±°
        cleaned_content = re.sub(r"\(ê·¸ë¦¼[^\)]*\)", "", content).strip()

        # ğŸ”„ ìì£¼í•˜ëŠ” ì§ˆë¬¸ â†’ Q/A ë¶„ë¦¬
        if section == "ìì£¼í•˜ëŠ” ì§ˆë¬¸":
            qa_split = split_qa_section(
                disease=disease,
                content=cleaned_content,
                page=chunk.get("page", 1)
            )
            new_chunks.extend(qa_split)
        else:
            new_chunks.append({
                "disease": disease,
                "section": section,
                "content": cleaned_content,
                "page": chunk.get("page", 1)
            })

    return new_chunks