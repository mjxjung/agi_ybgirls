# extractor.py

import re
from bs4 import BeautifulSoup
import os
import json
import pandas as pd
from datetime import datetime


def extract_disease_name(html: str) -> str:
    """
    HTML ë¬¸ìì—´ì—ì„œ ë³‘ëª…ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜

    1. <h1> íƒœê·¸ì—ì„œ ì¶”ì¶œ
    2. <p> ë˜ëŠ” <header> íƒœê·¸ ì¤‘ style="font-size:22px"ì—ì„œ ì¶”ì¶œ
    3. 'â€¢ ì½˜í…ì¸ ëª… :' í¬í•¨ëœ ë¬¸ì¥ì—ì„œ ì¶”ì¶œ

    Args:
        html (str): HTML ë¬¸ìì—´

    Returns:
        str: ì¶”ì¶œëœ ë³‘ëª… (ì—†ìœ¼ë©´ 'Unknown Disease')
    """
    soup = BeautifulSoup(html, 'html.parser')
    disease_name = ""

    # 1. <h1> íƒœê·¸ì—ì„œ ì¶”ì¶œ
    disease_tag = soup.find("h1")

    # 2. h1 íƒœê·¸ ì—†ì„ ê²½ìš°, font-size:22px ìŠ¤íƒ€ì¼ì´ ìˆëŠ” <p> ë˜ëŠ” <header>ì—ì„œ ì¶”ì¶œ
    if disease_tag is None:
        for tag in soup.find_all(["p", "header"]):
            style = tag.get("style", "")
            if "font-size:22px" in style:
                disease_tag = tag
                break

    # 3. ìµœì¢…ì ìœ¼ë¡œ ë³‘ëª… ì¶”ì¶œ
    if disease_tag:
        disease_name = disease_tag.get_text(strip=True)

    # 4. ê·¸ë˜ë„ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ, 'â€¢ ì½˜í…ì¸ ëª… :' í¬í•¨ëœ ë¬¸ì¥ì—ì„œ ì¶”ì¶œ
    if not disease_name:
        for tag in soup.find_all("p"):
            text = tag.get_text(strip=True)
            if "â€¢ ì½˜í…ì¸ ëª…" in text:
                match = re.search(r"ì½˜í…ì¸ ëª…\s*:\s*(.+)", text)
                if match:
                    disease_name = match.group(1).strip()
                    break

    return disease_name or "Unknown Disease"


def extract_sections(data: dict, disease_name: str) -> list[dict]:
    """
    ë¬¸ì„œ dataì—ì„œ ì„¹ì…˜ë³„ ë‚´ìš©ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜

    Args:
        data (dict): notebookì—ì„œ ë¶ˆëŸ¬ì˜¨ JSON ë°ì´í„°
        disease_name (str): ì¶”ì¶œëœ ë³‘ëª…

    Returns:
        list[dict]: ì„¹ì…˜ë³„ë¡œ ë‚˜ëˆˆ ë³‘ëª…, ì œëª©, ë³¸ë¬¸, í˜ì´ì§€ ì •ë³´ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸
    """
    chunks = []
    current_section = None
    current_text = []

    first_page_font_threshold = 22
    other_page_font_threshold = 18

    for elem in data.get('elements', []):
        html = elem.get("content", {}).get("html", "")
        text = BeautifulSoup(html, "html.parser").get_text(strip=True)
        page = elem.get("page", 1)
        category = elem.get("category", "")
        style = ""

        # style ì •ë³´ ì¶”ì¶œ
        soup = BeautifulSoup(html, "html.parser")
        tag = soup.find()
        if tag:
            style = tag.get("style", "")

        # font-size ì¶”ì¶œ
        font_size = 0
        if "font-size:" in style:
            try:
                font_size = int(style.split("font-size:")[1].replace("px", "").strip())
            except:
                pass

        # í˜ì´ì§€ë³„ ê¸°ì¤€ ì ìš©
        threshold = first_page_font_threshold if page == 1 else other_page_font_threshold
        is_heading = (category.startswith("heading") or font_size >= threshold)

        if not text:
            continue

        # âœ… <ê·¸ë¦¼ ...> ì„¹ì…˜ ì¶”ì¶œ
        if text.startswith("<ê·¸ë¦¼") and ">" in text:
            match = re.match(r"<(.*?)>(.*)", text)
            if match:
                fig_section = match.group(1).strip()
                fig_content = match.group(2).strip()

                chunks.append({
                    "disease": disease_name,
                    "section": fig_section,
                    "content": fig_content,
                    "page": page
                })
            continue

        if is_heading:
            if current_section and current_text:
                chunks.append({
                    "disease": disease_name,
                    "section": current_section,
                    "content": "\n".join(current_text),
                    "page": page
                })
                current_text = []
            current_section = text
        else:
            current_text.append(text)

    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
    if current_section and current_text:
        chunks.append({
            "disease": disease_name,
            "section": current_section,
            "content": "\n".join(current_text),
            "page": page
        })

    return chunks


def save_chunks_to_file(chunks: list[dict], folder_path: str, disease_name: str) -> None:
    """
    í´ë” ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„ chunksë¥¼ JSONê³¼ CSVë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.

    Parameters:
        chunks (list[dict]): ì„¹ì…˜ë³„ë¡œ ë¶„ë¥˜ëœ í…ìŠ¤íŠ¸ ë°ì´í„°
        folder_path (str): ì €ì¥í•  í´ë” ê²½ë¡œ
        disease_name (str): ë³‘ëª… (íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©ë¨)
    """
    # í´ë” ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(folder_path, exist_ok=True)

    # ë³‘ëª…ì— ë“¤ì–´ê°ˆ ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
    safe_disease_name = "".join(c for c in disease_name if c.isalnum() or c in (" ", "_", "-")).strip().replace(" ", "_")

    # íƒ€ì„ìŠ¤íƒ¬í”„ (optional, ì´ë¦„ ì¶©ëŒ ë°©ì§€ìš©)
    # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ì €ì¥ ê²½ë¡œ ì§€ì •
    json_path = os.path.join(folder_path, f"{safe_disease_name}.json")
    # csv_path = os.path.join(folder_path, f"{safe_disease_name}.csv")

    # ì €ì¥
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(chunks, f, ensure_ascii=False, indent=2)

    # pd.DataFrame(chunks).to_csv(csv_path, index=False)

    print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {json_path}")
    # print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {csv_path}")


def process_sections(chunks: list[dict]) -> list[dict]:
    """
    ì €ì¥ëœ ì„¹ì…˜ ë°ì´í„°ë¥¼ í›„ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    - ì§ˆë³‘ëª…ê³¼ ê°™ì€ ì œëª© ì œê±°
    - ê³µê³µëˆ„ë¦¬ ë¬¸êµ¬ ì œê±°
    - 'ìì£¼í•˜ëŠ” ì§ˆë¬¸' ì„¹ì…˜ì„ Q/A ìŒìœ¼ë¡œ ë¶„ë¦¬
    - ì„¹ì…˜ëª…ì´ 'ê·¸ë¦¼'ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì œì™¸
    - ë³¸ë¬¸ì— (ê·¸ë¦¼...) í˜•íƒœê°€ ìˆìœ¼ë©´ ì‚­ì œ

    Parameters:
        chunks (list[dict]): ì €ì¥ëœ ì„¹ì…˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸

    Returns:
        list[dict]: í›„ì²˜ë¦¬ëœ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
    """
    def split_qa_section(disease, content, page):
        qa_chunks = []
        content = content.replace("A.\\n", "A.\n").replace("\\n", "\n")
        qa_blocks = re.split(r"(Q\..*?)\nA\.", content)
        qa_blocks = [b.strip() for b in qa_blocks if b.strip()]

        for i in range(0, len(qa_blocks) - 1, 2):
            question = qa_blocks[i]
            answer = qa_blocks[i + 1]
            qa_chunks.append({
                "disease": disease,
                "section": question,
                "content": answer,
                "page": page
            })
        return qa_chunks

    PUBLIC_NOTICE = 'ë³¸ ê³µê³µì €ì‘ë¬¼ì€ ê³µê³µëˆ„ë¦¬ "ì¶œì²˜í‘œì‹œ+ìƒì—…ì ì´ìš©ê¸ˆì§€+ë³€ê²½ê¸ˆì§€" ì¡°ê±´ì— ë”°ë¼ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
    new_chunks = []

    for chunk in chunks:
        disease = chunk["disease"]
        section = chunk["section"].strip()
        content = chunk["content"].strip()

        # âŒ ì„¹ì…˜ëª…ì´ ì§ˆë³‘ëª…ê³¼ ê°™ê±°ë‚˜ ê³µê³µëˆ„ë¦¬ ë¬¸êµ¬ì´ê±°ë‚˜ 'ê·¸ë¦¼'ìœ¼ë¡œ ì‹œì‘ â†’ ì œì™¸
        if section == disease or section == PUBLIC_NOTICE or section.startswith("ê·¸ë¦¼"):
            continue

        # âœ… ë³¸ë¬¸ì—ì„œ (ê·¸ë¦¼ ...) í˜•íƒœ ì œê±°
        cleaned_content = re.sub(r"\(ê·¸ë¦¼[^\)]*\)", "", content).strip()

        # ğŸ”„ 'ìì£¼í•˜ëŠ” ì§ˆë¬¸' ì„¹ì…˜ â†’ Q/A ë¶„ë¦¬
        if section == "ìì£¼í•˜ëŠ” ì§ˆë¬¸":
            qa_split = split_qa_section(
                disease=disease,
                content=cleaned_content,
                page=chunk.get("page", 1)
            )
            new_chunks.extend(qa_split)
        else:
            new_chunks.append({
                "disease": disease,
                "section": section,
                "content": cleaned_content,
                "page": chunk.get("page", 1)
            })

    return new_chunks