# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
from dotenv import load_dotenv

# API í‚¤ ì •ë³´ ë¡œë“œ
load_dotenv()

import os
import json
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document

# 1. JSON íŒŒì¼ ì½ê¸° â†’ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
def load_json_documents(json_folder_path):
    documents = []
    for filename in os.listdir(json_folder_path):
        if filename.endswith(".json"):
            with open(os.path.join(json_folder_path, filename), "r", encoding="utf-8") as f:
                data = json.load(f)
                for item in data:
                    content = item.get("content", "")
                    metadata = {
                        "disease": item.get("disease", ""),
                        "section": item.get("section", ""),
                        "page": item.get("page", "")
                    }
                    documents.append(Document(page_content=content, metadata=metadata))
    return documents

# ê²½ë¡œ ì„¤ì •
json_path = "disease_data"
 # ì—¬ê¸°ì— JSON íŒŒì¼ ì—¬ëŸ¬ ê°œê°€ ë“¤ì–´ ìˆëŠ” í´ë” ê²½ë¡œë¥¼ ë„£ìœ¼ì„¸ìš”.

# 2. ë¬¸ì„œ ë¡œë“œ
docs = load_json_documents(json_path)

# 3. ë¬¸ì„œ ë¶„í• 
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
split_docs = splitter.split_documents(docs)

# 4. ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(split_docs, embeddings)

# 5. ê²€ìƒ‰ê¸°
retriever = vectorstore.as_retriever()

# 6. í”„ë¡¬í”„íŠ¸ ì •ì˜
prompt = PromptTemplate.from_template(
    """ë„ˆëŠ” ì§ˆë³‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” ë„ìš°ë¯¸ì•¼.
ì•„ë˜ì˜ contextë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µí•´ì¤˜. ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´.
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜.

ì§ˆë¬¸: {question}

ì •ë³´:
{context}

ë‹µë³€:"""
)

# 7. LLM ì„¤ì •
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# 8. ì²´ì¸ êµ¬ì„±
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 9. í…ŒìŠ¤íŠ¸
while True:
    question = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit'): ")
    if question.lower() == "exit":
        break
    answer = chain.invoke(question)
    print("\nğŸ“˜ ë‹µë³€:\n", answer)
