# llm_api.py
from openai import OpenAI
from dotenv import load_dotenv
import os

# ğŸ”‘ API Key ì„¤ì •
load_dotenv()
client = OpenAI()

def ask_disease_recommendation(symptom: str) -> dict:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜í•™ ì „ë¬¸ AIì…ë‹ˆë‹¤. ì‚¬ìš©ì ì¦ìƒì— ë§ëŠ” ì§ˆë³‘ 3ê°€ì§€ë¥¼ ì¶”ì²œí•˜ì„¸ìš”."},
            {"role": "user", "content": f"ì¦ìƒ: {symptom}"}
        ]
    )
    content = response.choices[0].message.content
    choices = [c.strip() for c in content.split(",")[:3]]

    return {
        "message": content,
        "choices": choices
    }

def ask_doctor_info(disease: str) -> dict:
    prompt = f"""
'{disease}'ì— ëŒ€í•´ ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ì „ë¬¸ì˜ë¥¼ ì´ë¦„, ì§„ë£Œê³¼, ì „ë¬¸ë¶„ì•¼ë¡œ 2ëª… ì†Œê°œí•´ì£¼ì„¸ìš”.
ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì€ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„í•´ì¤˜:

[
    {{"name": "ì´ë¦„", "department": "ì§„ë£Œê³¼", "specialty": "ì „ë¬¸ë¶„ì•¼"}},
    ...
]
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜í•™ ì „ë¬¸ AIì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”."},
            {"role": "user", "content": prompt}
        ]
    )
    text = response.choices[0].message.content

    try:
        doctors = eval(text)  # LLMì´ í¬ë§· ë§ì¶°ì£¼ë©´ OK (ì£¼ì˜: í”„ë¡œë•ì…˜ì—ì„  `ast.literal_eval()` ì¨ì•¼ ì•ˆì „)
    except:
        doctors = []

    return {
        "message": f"'{disease}' ê´€ë ¨ ì „ë¬¸ì˜ë¥¼ ì•ˆë‚´ë“œë¦´ê²Œìš”:",
        "doctors": doctors
    }
